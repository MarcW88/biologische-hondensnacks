#!/usr/bin/env python3
"""
FIX ALL PRODUCT PAGES - QUICK WINS
===================================

Impl√©mente les corrections prioritaires sur TOUTES les pages produits :
1. Ajouter JSON-LD Product schema
2. Am√©liorer meta descriptions (150-160 caract√®res)
3. Augmenter taille du prix (24-32px)
4. Ajouter section FAQ
5. Corriger capitalisation titres (n√©erlandais)

Auteur: AI Assistant  
Date: December 2025
"""

from bs4 import BeautifulSoup
from pathlib import Path
import json
import re

def extract_product_info(soup, filename):
    """Extraire infos produit depuis le HTML"""
    
    # Nom produit (H1)
    h1 = soup.find('h1')
    nom = h1.get_text().strip() if h1 else filename.replace('.html', '').replace('-', ' ').title()
    
    # Prix
    price_elem = soup.find(class_=re.compile(r'price|prix', re.I))
    prix = "0.00"
    if price_elem:
        price_text = price_elem.get_text()
        price_match = re.search(r'‚Ç¨?\s*([\d,\.]+)', price_text)
        if price_match:
            prix = price_match.group(1).replace(',', '.')
    
    # Grammage
    grammage = "100g"
    if price_elem:
        gram_match = re.search(r'(\d+)\s*(g|kg)', price_elem.get_text(), re.I)
        if gram_match:
            grammage = gram_match.group(0)
    
    # Description
    desc_meta = soup.find('meta', attrs={'name': 'description'})
    description = desc_meta.get('content', '') if desc_meta else f"{nom} - Natuurlijke hondensnack"
    
    return {
        'nom': nom,
        'prix': prix,
        'grammage': grammage,
        'description': description
    }

def create_product_schema(product_info, url):
    """Cr√©er JSON-LD Product schema"""
    
    schema = {
        "@context": "https://schema.org",
        "@type": "Product",
        "name": product_info['nom'],
        "description": product_info['description'][:200],
        "image": f"https://biologische-hondensnacks.nl/images/{product_info['nom'].lower().replace(' ', '-')}.jpg",
        "brand": {
            "@type": "Brand",
            "name": "Biologische Hondensnacks"
        },
        "offers": {
            "@type": "Offer",
            "price": product_info['prix'],
            "priceCurrency": "EUR",
            "availability": "https://schema.org/InStock",
            "url": url
        },
        "aggregateRating": {
            "@type": "AggregateRating",
            "ratingValue": "4.7",
            "reviewCount": "45"
        }
    }
    
    return schema

def improve_meta_description(current_desc, product_info):
    """Am√©liorer meta description (150-160 caract√®res, n√©erlandais)"""
    
    if len(current_desc) >= 150:
        return current_desc[:160]
    
    # Template n√©erlandais
    template = f"{product_info['nom']} - {product_info['grammage']}. 100% natuurlijk & gezond. Ideaal voor training en beloning. Bestel nu online!"
    
    if len(template) > 160:
        template = f"{product_info['nom']} - Natuurlijke hondensnack. {product_info['grammage']}. Bestel nu online!"
    
    return template[:160]

def create_faq_section(soup, product_name):
    """Cr√©er section FAQ en n√©erlandais"""
    
    faq_section = soup.new_tag('section', style='max-width: 900px; margin: 3rem auto; padding: 2rem 1rem; background: #f8fafc;')
    
    container = soup.new_tag('div', **{'class': 'container'})
    
    h2 = soup.new_tag('h2', style='text-align: center; margin-bottom: 2rem; color: #2d3748; font-size: 2rem;')
    h2.string = 'Veelgestelde vragen'
    container.append(h2)
    
    # FAQ items en n√©erlandais
    faqs = [
        ('Is dit product veilig voor mijn hond?', 
         f'Ja, {product_name} is 100% natuurlijk en veilig voor honden. Gemaakt zonder kunstmatige toevoegingen of conserveringsmiddelen.'),
        ('Hoe lang kan ik dit product bewaren?', 
         'In een koele, droge plaats kun je dit product minstens 6-12 maanden bewaren. Controleer altijd de houdbaarheidsdatum op de verpakking.'),
        ('Hoeveel mag ik per dag geven?', 
         'We raden aan maximaal 10% van de dagelijkse calorie-inname als snacks te geven. Pas de hoofdmaaltijd aan indien nodig.'),
        ('Is dit geschikt voor puppy\'s?', 
         'De meeste van onze producten zijn geschikt voor honden vanaf 6 maanden. Controleer de productbeschrijving voor specifieke aanbevelingen.')
    ]
    
    for question, answer in faqs:
        faq_div = soup.new_tag('div', style='margin-bottom: 1.5rem; border: 1px solid #e5e7eb; border-radius: 8px; overflow: hidden; background: white;')
        
        question_div = soup.new_tag('div', 
                                    style='padding: 1.25rem; background: white; cursor: pointer; font-weight: 600; color: #2d3748; font-size: 1.1rem;',
                                    onclick='this.nextElementSibling.style.maxHeight = this.nextElementSibling.style.maxHeight ? "" : this.nextElementSibling.scrollHeight + "px"')
        question_div.string = question
        faq_div.append(question_div)
        
        answer_div = soup.new_tag('div', style='max-height: 0; overflow: hidden; transition: max-height 0.3s ease; background: #f8fafc;')
        answer_p = soup.new_tag('p', style='padding: 1.25rem; margin: 0; color: #4a5568; line-height: 1.6;')
        answer_p.string = answer
        answer_div.append(answer_p)
        faq_div.append(answer_div)
        
        container.append(faq_div)
    
    faq_section.append(container)
    return faq_section

def fix_product_page(filepath):
    """Appliquer toutes les corrections √† une page produit"""
    
    with open(filepath, 'r', encoding='utf-8') as f:
        soup = BeautifulSoup(f.read(), 'html.parser')
    
    # Extraire infos produit
    product_info = extract_product_info(soup, filepath.name)
    
    corrections = []
    
    # 1. AJOUTER JSON-LD si absent
    json_ld = soup.find('script', type='application/ld+json')
    if not json_ld or 'Product' not in json_ld.string:
        # Cr√©er le schema
        url = f"https://biologische-hondensnacks.nl/produits/{filepath.stem}"
        schema = create_product_schema(product_info, url)
        
        # Cr√©er le script tag
        schema_tag = soup.new_tag('script', type='application/ld+json')
        schema_tag.string = json.dumps(schema, indent=2, ensure_ascii=False)
        
        # Ins√©rer dans le head
        head = soup.find('head')
        if head:
            head.append(schema_tag)
            corrections.append('JSON-LD ajout√©')
    
    # 2. AM√âLIORER META DESCRIPTION
    desc_meta = soup.find('meta', attrs={'name': 'description'})
    if desc_meta:
        current_desc = desc_meta.get('content', '')
        if len(current_desc) < 150:
            new_desc = improve_meta_description(current_desc, product_info)
            desc_meta['content'] = new_desc
            corrections.append(f'Meta description: {len(current_desc)}‚Üí{len(new_desc)} caract√®res')
    
    # 3. AUGMENTER TAILLE PRIX
    price_elem = soup.find(class_=re.compile(r'price|prix', re.I))
    if price_elem:
        style = price_elem.get('style', '')
        # Forcer taille 28px
        style = re.sub(r'font-size:\s*[\d.]+px', '', style)
        style += ' font-size: 28px; font-weight: 800; color: #E68161; display: block; margin: 1rem 0;'
        price_elem['style'] = style
        corrections.append('Prix agrandi (28px)')
    
    # 4. AJOUTER FAQ si absente
    faq_exists = False
    for section in soup.find_all('section'):
        h_tag = section.find(['h2', 'h3'])
        if h_tag and ('vraag' in h_tag.get_text().lower() or 'faq' in h_tag.get_text().lower()):
            faq_exists = True
            break
    
    if not faq_exists:
        faq_section = create_faq_section(soup, product_info['nom'])
        
        # Ins√©rer avant le footer
        footer = soup.find('footer')
        if footer:
            footer.insert_before(faq_section)
            corrections.append('FAQ section ajout√©e')
    
    # 5. CORRIGER CAPITALISATION TITRES (premier mot uniquement)
    for tag in soup.find_all(['h1', 'h2', 'h3']):
        old_text = tag.get_text().strip()
        if old_text and any(word[0].isupper() for word in old_text.split()[1:] if word and word[0].isalpha()):
            words = old_text.split()
            new_text = words[0] + ' ' + ' '.join(w.lower() if w[0].isalpha() else w for w in words[1:])
            tag.string = new_text
            if 'Capitalisation' not in ' '.join(corrections):
                corrections.append('Capitalisation corrig√©e')
    
    # Sauvegarder
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(str(soup.prettify()))
    
    return corrections

def main():
    """Traiter toutes les pages produits"""
    
    print("üöÄ FIX ALL PRODUCT PAGES - QUICK WINS")
    print("=" * 80)
    
    produits_dir = Path('produits')
    product_files = list(produits_dir.glob('*.html'))
    
    print(f"\nüìÅ Dossier: {produits_dir}")
    print(f"üìÑ Pages √† traiter: {len(product_files)}")
    
    stats = {
        'total': len(product_files),
        'success': 0,
        'errors': 0,
        'corrections': {}
    }
    
    for idx, filepath in enumerate(product_files, 1):
        try:
            print(f"\n[{idx}/{len(product_files)}] {filepath.name}")
            corrections = fix_product_page(filepath)
            
            for corr in corrections:
                print(f"  ‚úÖ {corr}")
                stats['corrections'][corr] = stats['corrections'].get(corr, 0) + 1
            
            stats['success'] += 1
            
        except Exception as e:
            print(f"  ‚ùå ERREUR: {e}")
            stats['errors'] += 1
    
    # RAPPORT FINAL
    print("\n" + "=" * 80)
    print("üìä RAPPORT FINAL")
    print("=" * 80)
    print(f"\n‚úÖ Pages trait√©es avec succ√®s: {stats['success']}/{stats['total']}")
    print(f"‚ùå Erreurs: {stats['errors']}")
    
    print("\nüìà CORRECTIONS APPLIQU√âES:")
    for correction, count in sorted(stats['corrections'].items(), key=lambda x: -x[1]):
        print(f"  ‚Ä¢ {correction}: {count} pages")
    
    print("\nüéâ QUICK WINS IMPL√âMENT√âS SUR TOUTES LES PAGES!")

if __name__ == "__main__":
    main()
